{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Seizures From EEG Data: Data Preparation\n",
    "\n",
    "#### Author: Burak Himmetoglu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will discuss how the raw data is processed and prepared. There are two types of data prepapation strategies that we use:\n",
    "\n",
    "* Manually engineered features\n",
    "* Averaged time series for LSTM\n",
    "\n",
    "In the first strategy, we basically follow traditional signal processing methods to engineer features from the raw time-series data. This approach is explored in another [notebook](https://github.com/bhimmetoglu/time-series-medicine/blob/master/EEG/explore.ipynb) in the repository. \n",
    "\n",
    "In the second strategy, we simply reduce the number of time-steps in the data by performing 1-dimensional convolutions with averages. This results in a shorther time-series that we can use as an input to a LSTM network.\n",
    "\n",
    "Let's first load the data for an example input (Dog 1) and compare both strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Construction of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.get_prepare_data_full import * \n",
    "from utils.lstm_utils import *\n",
    "%matplotlib inline\n",
    "\n",
    "# Read data\n",
    "clips_interictal, clips_preictal, clips_test = get_data(data_folder = \"../data/Dog_1/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preictal** clips correspond to the time-series segments of the measurement before a seizure occurs (usually, segments 90 min before a seiuzure is labeled as preictal). **Interictal** clips are instead segments with no oncoming seizures.  \n",
    "\n",
    "There are different channels where measurements are performed. In this example, there are 16 channels. In each channel, a sampling frequency determines how many data points are in 1 second (600 Hz in this example). The sampling frequency multiplied with the total measurement time per clip (~400 s in this example) determines the length of each time-series (around 240,000). Let's summarize:\n",
    "\n",
    "$$ n_{ch} = 16 $$\n",
    "\n",
    "$$ T = 400\\, s $$\n",
    "\n",
    "$$ f_{s} = 600\\, {\\rm Hz} $$\n",
    "\n",
    "From this time-series, we can construct features in a variety of ways (see [notebook](https://github.com/bhimmetoglu/time-series-medicine/blob/master/EEG/explore.ipynb) for some choices). Here, we focus on feature engineering that are adapted from a [Matlab solution](https://github.com/drewabbot/kaggle-seizure-prediction). \n",
    "\n",
    "We first split each segment into blocks of 60s. Within each block, power spectra within 6 frequency bands  are computed. These power spectra are used to consruct the following features\n",
    "\n",
    "* Eigenvalues of the correlation matrix between bands and channels within each block\n",
    "* Shannon's entropy for the power within each block\n",
    "* Power at dyadic levels, the eigenvalues of their correlation between channels and Shannon's entropy\n",
    "* [Hjorth parameters](https://en.wikipedia.org/wiki/Hjorth_parameters)\n",
    "* Skewness and Kurtosis within each block\n",
    "\n",
    "The code for constructing these featues can be found in [get_prepare_data_full.py](https://github.com/bhimmetoglu/time-series-medicine/blob/master/EEG/utils/get_prepare_data_full.py). Let's construct the above features using these utilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Frequency bands\n",
    "freq_bands = np.array([0.1, 4, 8, 12, 30, 70, 180])\n",
    "\n",
    "X_0, Y_0, _ = features(clips_interictal, 0, freq_bands)\n",
    "X_1, Y_1, _ = features(clips_preictal, 1, freq_bands)\n",
    "\n",
    "# Let's combine\n",
    "X = np.concatenate((X_0, X_1), axis=0)\n",
    "Y = np.squeeze(np.concatenate((Y_0, Y_1), axis=0)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the number of instances, number of features and the percentage of positive (preictal) labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 3024, Number of features 166\n",
      "Percentage of positive labels= 4.761905\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of instances: {:d}, Number of features {:d}\".format(X.shape[0], X.shape[1]))\n",
    "print(\"Percentage of positive labels= {:4f}\".format(np.sum(Y)/len(Y)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have around 3000 data points and 166 features. Only 5% of the labels are positive, so the labels are very inbalanced. This inbalance can introduce issues, so we need to take special care when building models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaged Time Series for LSTM\n",
    "\n",
    "Now, we will construct inputs for a LSTM network using the raw data. The data has to be in reshaped into (N, seq_len, n_channels) where\n",
    "\n",
    "* N: Number of data points\n",
    "* seq_len : The sequence length for time-series\n",
    "* n_channels : Number of channels\n",
    "\n",
    "The problem that we face the raw data sequence is very long for LSTM. For example, in the Dog 1 data, there are approximately $400 \\times 600 =  24,0000$ points in time. This is very long and typical LSTM cells can not be trained for such long series. Therefore, we use 1d convolutions to reduce the number of points, which is shown schematically below:\n",
    "\n",
    "![title](img/eeg.002.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, within each block (of 60 s data), we move a window with a given stride and average the values within each window. This reduces the number of time steps. However, the downside is that the size of the window and the strides become hyperparameters to be tuned. After this step, the data is then collected in the desired shape. \n",
    "\n",
    "The code for constructing these featues can be found in [lstm_utils.py](https://github.com/bhimmetoglu/seizure-forecast/blob/master/utils/lstm_utils.py). Let's now construct the time average data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Window, stride and block_s\n",
    "window = 16000 # an interval encompassing ~ 26 s\n",
    "stride = 100\n",
    "block_s = 60 \n",
    "\n",
    "X_1, Y_1, n_blocks = lstm_build_input(clips_preictal, 1, window, stride)\n",
    "X_0, Y_0, n_blocks = lstm_build_input(clips_interictal, 0, window, stride)\n",
    "\n",
    "# Scale the data, and then combine\n",
    "X_1 = X_1 / np.max(np.abs(X_1), axis=1)[:,None,:]\n",
    "X_0 = X_0 / np.max(np.abs(X_0), axis=1)[:,None,:]\n",
    "\n",
    "# Combine the data  \n",
    "X = np.concatenate((X_0, X_1), axis = 0)\n",
    "Y = np.concatenate((Y_0, Y_1), axis = 0)\n",
    "Y = np.squeeze(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have chosen a window of approximate size of 26 s and 100 points for the strides. The resulting data has the following dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape =  (3024, 200, 16)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data shape = \", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which shows that seq_len = 200. This is an acceptable value which a typical LSTM network can handle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
