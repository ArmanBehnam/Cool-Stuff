{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp rocket_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rocket functions\n",
    "\n",
    "> ROCKET (RandOm Convolutional KErnel Transform) functions for univariate and multivariate time series using GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tsai.imports import *\n",
    "from tsai.data.external import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from numba import njit, prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Angus Dempster, Francois Petitjean, Geoff Webb\n",
    "\n",
    "# Dempster A, Petitjean F, Webb GI (2019) ROCKET: Exceptionally fast and\n",
    "# accurate time series classification using random convolutional kernels.\n",
    "# arXiv:1910.13051\n",
    "\n",
    "# changes: \n",
    "# - added kss parameter to generate_kernels\n",
    "# - convert X to np.float64\n",
    "\n",
    "def generate_kernels(input_length, num_kernels, kss=[7, 9, 11], pad=True, dilate=True):\n",
    "    candidate_lengths = np.array((kss))\n",
    "    # initialise kernel parameters\n",
    "    weights = np.zeros((num_kernels, candidate_lengths.max())) # see note\n",
    "    lengths = np.zeros(num_kernels, dtype = np.int32) # see note\n",
    "    biases = np.zeros(num_kernels)\n",
    "    dilations = np.zeros(num_kernels, dtype = np.int32)\n",
    "    paddings = np.zeros(num_kernels, dtype = np.int32)\n",
    "    # note: only the first *lengths[i]* values of *weights[i]* are used\n",
    "    for i in range(num_kernels):\n",
    "        length = np.random.choice(candidate_lengths)\n",
    "        _weights = np.random.normal(0, 1, length)\n",
    "        bias = np.random.uniform(-1, 1)\n",
    "        if dilate: dilation = 2 ** np.random.uniform(0, np.log2((input_length - 1) // (length - 1)))\n",
    "        else: dilation = 1\n",
    "        if pad: padding = ((length - 1) * dilation) // 2 if np.random.randint(2) == 1 else 0\n",
    "        else: padding = 0\n",
    "        weights[i, :length] = _weights - _weights.mean()\n",
    "        lengths[i], biases[i], dilations[i], paddings[i] = length, bias, dilation, padding\n",
    "    return weights, lengths, biases, dilations, paddings\n",
    "\n",
    "@njit(fastmath = True)\n",
    "def apply_kernel(X, weights, length, bias, dilation, padding):\n",
    "    # zero padding\n",
    "    if padding > 0:\n",
    "        _input_length = len(X)\n",
    "        _X = np.zeros(_input_length + (2 * padding))\n",
    "        _X[padding:(padding + _input_length)] = X\n",
    "        X = _X\n",
    "    input_length = len(X)\n",
    "    output_length = input_length - ((length - 1) * dilation)\n",
    "    _ppv = 0 # \"proportion of positive values\"\n",
    "    _max = np.NINF\n",
    "    for i in range(output_length):\n",
    "        _sum = bias\n",
    "        for j in range(length):\n",
    "            _sum += weights[j] * X[i + (j * dilation)]\n",
    "        if _sum > 0:\n",
    "            _ppv += 1\n",
    "        if _sum > _max:\n",
    "            _max = _sum\n",
    "    return _ppv / output_length, _max\n",
    "\n",
    "@njit(parallel = True, fastmath = True)\n",
    "def apply_kernels(X, kernels):\n",
    "    X = X.astype(np.float64)\n",
    "    weights, lengths, biases, dilations, paddings = kernels\n",
    "    num_examples = len(X)\n",
    "    num_kernels = len(weights)\n",
    "    # initialise output\n",
    "    _X = np.zeros((num_examples, num_kernels * 2)) # 2 features per kernel\n",
    "    for i in prange(num_examples):\n",
    "        for j in range(num_kernels):\n",
    "            _X[i, (j * 2):((j * 2) + 2)] = \\\n",
    "            apply_kernel(X[i], weights[j][:lengths[j]], lengths[j], biases[j], dilations[j], paddings[j])\n",
    "    return _X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "X_train, y_train, X_valid, y_valid = get_UCR_data('OliveOil')\n",
    "seq_len = X_train.shape[-1]\n",
    "X_train = X_train[:, 0].astype(np.float64)\n",
    "X_valid = X_valid[:, 0].astype(np.float64)\n",
    "labels = np.unique(y_train)\n",
    "transform = {}\n",
    "for i, l in enumerate(labels): transform[l] = i\n",
    "y_train = np.vectorize(transform.get)(y_train).astype(np.int32)\n",
    "y_valid = np.vectorize(transform.get)(y_valid).astype(np.int32)\n",
    "X_train = (X_train - X_train.mean(axis = 1, keepdims = True)) / (X_train.std(axis = 1, keepdims = True) + 1e-8)\n",
    "X_valid = (X_valid - X_valid.mean(axis = 1, keepdims = True)) / (X_valid.std(axis = 1, keepdims = True) + 1e-8)\n",
    "\n",
    "# only univariate time series of shape (samples, len)\n",
    "kernels = generate_kernels(seq_len, 10000)\n",
    "X_train_tfm = apply_kernels(X_train, kernels)\n",
    "X_valid_tfm = apply_kernels(X_valid, kernels)\n",
    "classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 7), normalize=True)\n",
    "classifier.fit(X_train_tfm, y_train)\n",
    "score = classifier.score(X_valid_tfm, y_valid)\n",
    "test_eq(ge(score,.9), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ROCKET(nn.Module):\n",
    "    def __init__(self, c_in, seq_len, n_kernels=10000, kss=[7, 9, 11]):\n",
    "        \n",
    "        '''\n",
    "        ROCKET is a GPU Pytorch implementation of the ROCKET methods generate_kernels \n",
    "        and apply_kernels that can be used  with univariate and multivariate time series.\n",
    "        Input: is a 3d torch tensor of type torch.float32. When used with univariate TS, \n",
    "        make sure you transform the 2d to 3d by adding unsqueeze(1).\n",
    "        c_in: number of channels or features. For univariate c_in is 1.\n",
    "        seq_len: sequence length\n",
    "        '''\n",
    "        super().__init__()\n",
    "        kss = [ks for ks in kss if ks < seq_len]\n",
    "        convs = nn.ModuleList()\n",
    "        for i in range(n_kernels):\n",
    "            ks = np.random.choice(kss)\n",
    "            dilation = 2**np.random.uniform(0, np.log2((seq_len - 1) // (ks - 1)))\n",
    "            padding = int((ks - 1) * dilation // 2) if np.random.randint(2) == 1 else 0\n",
    "            weight = torch.randn(1, c_in, ks)\n",
    "            weight -= weight.mean()\n",
    "            bias = 2 * (torch.rand(1) - .5)\n",
    "            layer = nn.Conv1d(c_in, 1, ks, padding=2 * padding, dilation=int(dilation), bias=True)\n",
    "            layer.weight = torch.nn.Parameter(weight, requires_grad=False)\n",
    "            layer.bias = torch.nn.Parameter(bias, requires_grad=False)\n",
    "            convs.append(layer)\n",
    "        self.convs = convs\n",
    "        self.n_kernels = n_kernels\n",
    "        self.kss = kss\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.n_kernels):\n",
    "            out = self.convs[i](x)\n",
    "            _max = out.max(dim=-1).values\n",
    "            _ppv = torch.gt(out, 0).sum(dim=-1).float() / out.shape[-1]\n",
    "            cat = torch.cat((_max, _ppv), dim=-1)\n",
    "            output = cat if i == 0 else torch.cat((output, cat), dim=-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "out = create_scripts()\n",
    "beep(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
