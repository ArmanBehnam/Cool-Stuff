{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet\n",
    "\n",
    "> This is an unofficial PyTorch implementation by Ignacio Oguiza - oguiza@gmail.com based on:\n",
    "* Wang, Z., Yan, W., & Oates, T. (2017, May). Time series classification from scratch with deep neural networks: A strong baseline. In 2017 international joint conference on neural networks (IJCNN) (pp. 1578-1585). IEEE.\n",
    "* Fawaz, H. I., Forestier, G., Weber, J., Idoumghar, L., & Muller, P. A. (2019). Deep learning for time series classification: a review. Data Mining and Knowledge Discovery, 33(4), 917-963.\n",
    "* Official ResNet TensorFlow implementation: https://github.com/hfawaz/dl-4-tsc\n",
    "* ðŸ‘€ kernel filter size 8 has been replaced by 7 (I believe it's a bug since even kernels are not commonly used in practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tsai.imports import *\n",
    "from tsai.models.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResBlock(Module):\n",
    "    def __init__(self, ni, nf, ks=[7, 5, 3]):\n",
    "        self.conv1 = Conv1d(ni, nf, ks[0], padding='same', act_fn='relu')\n",
    "        self.conv2 = Conv1d(nf, nf, ks[1], padding='same', act_fn='relu')\n",
    "        self.conv3 = Conv1d(nf, nf, ks[2], padding='same', act_fn='relu')\n",
    "\n",
    "        # expand channels for the sum if necessary\n",
    "        self.shortcut = noop if ni == nf else Conv1d(ni, nf, ks=1, act_fn=False)\n",
    "        self.act_fn = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        sc = self.shortcut(res)\n",
    "        x += sc\n",
    "        x = self.act_fn(x)\n",
    "        return x\n",
    "    \n",
    "class ResNet(Module):\n",
    "    def __init__(self,c_in, c_out):\n",
    "        nf = 64\n",
    "        self.block1 = ResBlock(c_in, nf, ks=[7, 5, 3])\n",
    "        self.block2 = ResBlock(nf, nf * 2, ks=[7, 5, 3])\n",
    "        self.block3 = ResBlock(nf * 2, nf * 2, ks=[7, 5, 3])\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "        self.squeeze = Squeeze(-1)\n",
    "        self.fc = nn.Linear(nf * 2, c_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.squeeze(self.gap(x))\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (block1): ResBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): ConvSP1d(\n",
       "        (conv): Conv1d(3, 64, kernel_size=(7,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): ConvSP1d(\n",
       "        (conv): Conv1d(64, 64, kernel_size=(5,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): ConvSP1d(\n",
       "        (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (shortcut): Sequential(\n",
       "      (0): ConvSP1d(\n",
       "        (conv): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act_fn): ReLU()\n",
       "  )\n",
       "  (block2): ResBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): ConvSP1d(\n",
       "        (conv): Conv1d(64, 128, kernel_size=(7,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): ConvSP1d(\n",
       "        (conv): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): ConvSP1d(\n",
       "        (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (shortcut): Sequential(\n",
       "      (0): ConvSP1d(\n",
       "        (conv): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act_fn): ReLU()\n",
       "  )\n",
       "  (block3): ResBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): ConvSP1d(\n",
       "        (conv): Conv1d(128, 128, kernel_size=(7,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): ConvSP1d(\n",
       "        (conv): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): ConvSP1d(\n",
       "        (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (act_fn): ReLU()\n",
       "  )\n",
       "  (gap): AdaptiveAvgPool1d(output_size=1)\n",
       "  (squeeze): Squeeze()\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb = torch.rand(16, 3, 128)\n",
    "test_eq(ResNet(3,2)(xb).shape, [xb.shape[0], 2])\n",
    "ResNet(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "out = create_scripts()\n",
    "beep(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
