{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.external"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data External\n",
    "\n",
    "> Helper functions used to download and extract common time series datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tsai.imports import *\n",
    "from tsai.utils import * \n",
    "from tsai.data.validation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import tempfile\n",
    "try: from urllib import urlretrieve\n",
    "except ImportError: from urllib.request import urlretrieve\n",
    "import shutil\n",
    "from pyunpack import Archive\n",
    "from scipy.io import arff\n",
    "from sktime.utils.load_data import load_from_tsfile_to_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def decompress_from_url(url, target_dir=None, verbose=False):\n",
    "    #Download\n",
    "    try:\n",
    "        fname = os.path.basename(url)\n",
    "        tmpdir = tempfile.mkdtemp()\n",
    "        local_comp_fname = os.path.join(tmpdir, fname)\n",
    "        urlretrieve(url, local_comp_fname)\n",
    "    except:\n",
    "        shutil.rmtree(tmpdir)\n",
    "        if verbose: sys.stderr.write(\"Could not download url. Please, check url.\\n\")\n",
    "    \n",
    "    #Decompress\n",
    "    try:\n",
    "        if not os.path.exists(target_dir): os.makedirs(target_dir)\n",
    "        Archive(local_comp_fname).extractall(target_dir)\n",
    "        shutil.rmtree(tmpdir)\n",
    "        return target_dir\n",
    "    except:\n",
    "        shutil.rmtree(tmpdir)\n",
    "        if verbose: sys.stderr.write(\"Could not uncompress file, aborting.\\n\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_UCR_univariate_list():\n",
    "    return [\n",
    "        'ACSF1', 'Adiac', 'AllGestureWiimoteX', 'AllGestureWiimoteY',\n",
    "        'AllGestureWiimoteZ', 'ArrowHead', 'Beef', 'BeetleFly', 'BirdChicken',\n",
    "        'BME', 'Car', 'CBF', 'Chinatown', 'ChlorineConcentration',\n",
    "        'CinCECGTorso', 'Coffee', 'Computers', 'CricketX', 'CricketY',\n",
    "        'CricketZ', 'Crop', 'DiatomSizeReduction',\n",
    "        'DistalPhalanxOutlineAgeGroup', 'DistalPhalanxOutlineCorrect',\n",
    "        'DistalPhalanxTW', 'DodgerLoopDay', 'DodgerLoopGame',\n",
    "        'DodgerLoopWeekend', 'Earthquakes', 'ECG200', 'ECG5000', 'ECGFiveDays',\n",
    "        'ElectricDevices', 'EOGHorizontalSignal', 'EOGVerticalSignal',\n",
    "        'EthanolLevel', 'FaceAll', 'FaceFour', 'FacesUCR', 'FiftyWords',\n",
    "        'Fish', 'FordA', 'FordB', 'FreezerRegularTrain', 'FreezerSmallTrain',\n",
    "        'Fungi', 'GestureMidAirD1', 'GestureMidAirD2', 'GestureMidAirD3',\n",
    "        'GesturePebbleZ1', 'GesturePebbleZ2', 'GunPoint', 'GunPointAgeSpan',\n",
    "        'GunPointMaleVersusFemale', 'GunPointOldVersusYoung', 'Ham',\n",
    "        'HandOutlines', 'Haptics', 'Herring', 'HouseTwenty', 'InlineSkate',\n",
    "        'InsectEPGRegularTrain', 'InsectEPGSmallTrain', 'InsectWingbeatSound',\n",
    "        'ItalyPowerDemand', 'LargeKitchenAppliances', 'Lightning2',\n",
    "        'Lightning7', 'Mallat', 'Meat', 'MedicalImages', 'MelbournePedestrian',\n",
    "        'MiddlePhalanxOutlineAgeGroup', 'MiddlePhalanxOutlineCorrect',\n",
    "        'MiddlePhalanxTW', 'MixedShapesRegularTrain', 'MixedShapesSmallTrain',\n",
    "        'MoteStrain', 'NonInvasiveFetalECGThorax1',\n",
    "        'NonInvasiveFetalECGThorax2', 'OliveOil', 'OSULeaf',\n",
    "        'PhalangesOutlinesCorrect', 'Phoneme', 'PickupGestureWiimoteZ',\n",
    "        'PigAirwayPressure', 'PigArtPressure', 'PigCVP', 'PLAID', 'Plane',\n",
    "        'PowerCons', 'ProximalPhalanxOutlineAgeGroup',\n",
    "        'ProximalPhalanxOutlineCorrect', 'ProximalPhalanxTW',\n",
    "        'RefrigerationDevices', 'Rock', 'ScreenType', 'SemgHandGenderCh2',\n",
    "        'SemgHandMovementCh2', 'SemgHandSubjectCh2', 'ShakeGestureWiimoteZ',\n",
    "        'ShapeletSim', 'ShapesAll', 'SmallKitchenAppliances', 'SmoothSubspace',\n",
    "        'SonyAIBORobotSurface1', 'SonyAIBORobotSurface2', 'StarLightCurves',\n",
    "        'Strawberry', 'SwedishLeaf', 'Symbols', 'SyntheticControl',\n",
    "        'ToeSegmentation1', 'ToeSegmentation2', 'Trace', 'TwoLeadECG',\n",
    "        'TwoPatterns', 'UMD', 'UWaveGestureLibraryAll', 'UWaveGestureLibraryX',\n",
    "        'UWaveGestureLibraryY', 'UWaveGestureLibraryZ', 'Wafer', 'Wine',\n",
    "        'WordSynonyms', 'Worms', 'WormsTwoClass', 'Yoga'\n",
    "    ]\n",
    "\n",
    "test_eq(len(get_UCR_univariate_list()), 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_UCR_multivariate_list():\n",
    "    return [\n",
    "        'ArticularyWordRecognition', 'AtrialFibrillation', 'BasicMotions',\n",
    "        'CharacterTrajectories', 'Cricket', 'DuckDuckGeese', 'EigenWorms',\n",
    "        'Epilepsy', 'ERing', 'EthanolConcentration', 'FaceDetection',\n",
    "        'FingerMovements', 'HandMovementDirection', 'Handwriting', 'Heartbeat',\n",
    "        'InsectWingbeat', 'JapaneseVowels', 'Libras', 'LSST', 'MotorImagery',\n",
    "        'NATOPS', 'PEMS-SF', 'PenDigits', 'PhonemeSpectra', 'RacketSports',\n",
    "        'SelfRegulationSCP1', 'SelfRegulationSCP2', 'SpokenArabicDigits',\n",
    "        'StandWalkJump', 'UWaveGestureLibrary'\n",
    "    ]\n",
    "\n",
    "test_eq(len(get_UCR_multivariate_list()), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def stack_padding(arr):\n",
    "    def resize(row, size):\n",
    "        new = np.array(row)\n",
    "        new.resize(size)\n",
    "        return new\n",
    "    row_length = max(arr, key=len).__len__()\n",
    "    mat = np.array( [resize(row, row_length) for row in arr] )\n",
    "    return mat\n",
    "\n",
    "def get_UCR_data(dsid, path='.', parent_dir='data/UCR', verbose=False, drop_na=False, on_disk=True, return_split=True):\n",
    "    if verbose: print('Dataset:', dsid)\n",
    "    assert dsid in get_UCR_univariate_list() + get_UCR_multivariate_list(), f'{dsid} is not a UCR dataset'\n",
    "    full_parent_dir = Path(path)/parent_dir\n",
    "    full_tgt_dir = full_parent_dir/dsid\n",
    "    if not all([os.path.isfile(f'{full_parent_dir}/{dsid}/{fn}.npy') for fn in ['X_train', 'X_valid', 'y_train', 'y_valid', 'X', 'y']]):\n",
    "        if dsid in ['InsectWingbeat', 'DuckDuckGeese']:\n",
    "            if verbose: print('There are problems with the original zip file and data cannot correctly downloaded')\n",
    "            return None, None, None, None\n",
    "        src_website = 'http://www.timeseriesclassification.com/Downloads'\n",
    "        if verbose: print(f'Downloading and decompressing data to {full_tgt_dir}...')\n",
    "        decompress_from_url(f'{src_website}/{dsid}.zip', target_dir=full_tgt_dir, verbose=verbose)\n",
    "        if verbose: print('...data downloaded and decompressed')\n",
    "        X_train_df, y_train = load_from_tsfile_to_dataframe(full_tgt_dir/f'{dsid}_TRAIN.ts')\n",
    "        X_valid_df, y_valid = load_from_tsfile_to_dataframe(full_tgt_dir/f'{dsid}_TEST.ts')\n",
    "        X_train_ = []\n",
    "        X_valid_ = []\n",
    "        for i in range(X_train_df.shape[-1]): \n",
    "            X_train_.append(stack_padding(X_train_df[f'dim_{i}'])) # stack arrays even if they have different lengths\n",
    "            X_valid_.append(stack_padding(X_valid_df[f'dim_{i}']))\n",
    "        X_train = np.transpose(np.stack(X_train_, axis=-1), (0, 2, 1)).astype(np.float32)\n",
    "        X_valid = np.transpose(np.stack(X_valid_, axis=-1), (0, 2, 1)).astype(np.float32)\n",
    "        np.save(f'{full_tgt_dir}/X_train.npy', X_train)\n",
    "        np.save(f'{full_tgt_dir}/y_train.npy', y_train)\n",
    "        np.save(f'{full_tgt_dir}/X_valid.npy', X_valid)\n",
    "        np.save(f'{full_tgt_dir}/y_valid.npy', y_valid)\n",
    "        np.save(f'{full_tgt_dir}/X.npy', concat(X_train, X_valid))\n",
    "        np.save(f'{full_tgt_dir}/y.npy', concat(y_train, y_valid))\n",
    "        del X_train, X_valid, y_train, y_valid\n",
    "        delete_all_in_dir(full_tgt_dir, exception='.npy')\n",
    "        \n",
    "    mmap_mode='r+' if on_disk else None\n",
    "    X_train = np.load(f'{full_tgt_dir}/X_train.npy', mmap_mode=mmap_mode)\n",
    "    y_train = np.load(f'{full_tgt_dir}/y_train.npy', mmap_mode=mmap_mode)\n",
    "    X_valid = np.load(f'{full_tgt_dir}/X_valid.npy', mmap_mode=mmap_mode)\n",
    "    y_valid = np.load(f'{full_tgt_dir}/y_valid.npy', mmap_mode=mmap_mode)\n",
    "\n",
    "    if return_split: \n",
    "        if verbose: \n",
    "            print('X_train:', X_train.shape)\n",
    "            print('y_train:', y_train.shape)\n",
    "            print('X_valid:', X_valid.shape)\n",
    "            print('y_valid:', y_valid.shape, '\\n')\n",
    "        return X_train, y_train, X_valid, y_valid\n",
    "    else: \n",
    "        X = np.load(f'{full_tgt_dir}/X.npy', mmap_mode=mmap_mode)\n",
    "        y = np.load(f'{full_tgt_dir}/y.npy', mmap_mode=mmap_mode)\n",
    "        splits = get_predefined_splits(*[X_train, X_valid])\n",
    "        if verbose: \n",
    "            print('X      :', X .shape)\n",
    "            print('y      :', y .shape)\n",
    "            print('splits :', splits, '\\n')\n",
    "        return X, y, splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "PATH = Path(os.getcwd()).parent # Path to /data/UCR\n",
    "dsids = ['OliveOil', 'AtrialFibrillation'] # univariate and multivariate\n",
    "for dsid in dsids:\n",
    "    tgt_dir = PATH/f'data/UCR/{dsid}'\n",
    "    if os.path.isdir(tgt_dir): shutil.rmtree(tgt_dir)\n",
    "    test_eq(len(get_files(tgt_dir)), 0) # no file left\n",
    "    X_train, y_train, X_valid, y_valid = get_UCR_data(dsid, PATH, parent_dir='data/UCR')\n",
    "    test_eq(len(get_files(tgt_dir, '.npy')), 6)\n",
    "    test_eq(len(get_files(tgt_dir, '.npy')), len(get_files(tgt_dir))) # test no left file/ dir\n",
    "    del X_train, y_train, X_valid, y_valid\n",
    "    start = time.time()\n",
    "    X_train, y_train, X_valid, y_valid = get_UCR_data(dsid, PATH, parent_dir='data/UCR')\n",
    "    elapsed = time.time() - start\n",
    "    test_eq(elapsed < 1, True)\n",
    "    test_eq(X_train.ndim, 3)\n",
    "    test_eq(y_train.ndim, 1)\n",
    "    test_eq(X_valid.ndim, 3)\n",
    "    test_eq(y_valid.ndim, 1)\n",
    "    test_eq(len(get_files(tgt_dir, '.npy')), 6)\n",
    "    test_eq(len(get_files(tgt_dir, '.npy')), len(get_files(tgt_dir))) # test no left file/ dir\n",
    "    test_eq(X_train.ndim, 3)\n",
    "    test_eq(y_train.ndim, 1)\n",
    "    test_eq(X_valid.ndim, 3)\n",
    "    test_eq(y_valid.ndim, 1)\n",
    "    test_eq(X_train.dtype, np.float32)\n",
    "    test_eq(X_train.__class__.__name__, 'memmap')\n",
    "    del X_train, y_train, X_valid, y_valid\n",
    "    X_train, y_train, X_valid, y_valid = get_UCR_data(dsid, PATH, parent_dir='data/UCR', on_disk=False)\n",
    "    test_eq(X_train.__class__.__name__, 'ndarray')\n",
    "    del X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsid = 'NATOPS' \n",
    "X_train, y_train, X_valid, y_valid = get_UCR_data(dsid)\n",
    "X, y, splits = get_UCR_data(dsid, return_split=False)\n",
    "test_eq(X[splits[0]], X_train)\n",
    "test_eq(y[splits[1]], y_valid)\n",
    "test_eq(X[splits[0]], X_train)\n",
    "test_eq(y[splits[1]], y_valid)\n",
    "test_type(X, X_train)\n",
    "test_type(y, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 000_utils.ipynb.\n",
      "Converted 000b_data.validation.ipynb.\n",
      "Converted 001_data.external.ipynb.\n",
      "Converted 002_data.core.ipynb.\n",
      "Converted 003_data.transforms.ipynb.\n",
      "Converted 005_data.tabular.ipynb.\n",
      "Converted 007_metrics.ipynb.\n",
      "Converted 008_learner.ipynb.\n",
      "Converted 009_optimizer.ipynb.\n",
      "Converted 010_rocket_functions.ipynb.\n",
      "Converted 100_layers.ipynb.\n",
      "Converted 100b_models_utils.ipynb.\n",
      "Converted 101_ResNet.ipynb.\n",
      "Converted 102_InceptionTime.ipynb.\n",
      "Converted 103_FCN.ipynb.\n",
      "Converted 104_ResCNN.ipynb.\n",
      "Converted index.ipynb.\n",
      "\n",
      "\n",
      "Checking folder: /Users/nacho/Documents/Machine_Learning/Jupyter_Notebooks/timeseries/tsai\n",
      "Correct conversion! 😃\n",
      "Total elapsed time 24 s\n",
      "Fri, 01 May 2020 10:22:27 CEST\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "out = create_scripts()\n",
    "beep(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
