{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An astonishing variety of time series econometrics problems can\n",
    "be handled in one way or another by putting a model into state\n",
    "space form and applying the Kalman filter, providing optimal\n",
    "estimates of latent state variables conditioning on observed\n",
    "data and the loglikelihood of parameters. Better still, writing\n",
    "code to run through the Kalman filter recursions is very\n",
    "straightforward in many of the popular software packages (e.g.\n",
    "Python, MATLAB) and can be accomplished in fewer than 50 lines of code.\n",
    "\n",
    "Considering a time-invariant state-space model such\n",
    "as<sup>3</sup>:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y_t & = Z \\alpha_t + \\varepsilon_t \\qquad & \\varepsilon_t \\sim N(0, H) \\\\\\\n",
    "\\alpha_{t+1} & = T \\alpha_t + \\eta_t \\qquad & \\eta_t \\sim N(0, Q) \\\\\\\n",
    "\\alpha_0 & \\sim N(a_0, P_0) ~ \\text{known}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "the Kalman filter can be written as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def kalman_filter(y, Z, H, T, Q, a_0, P_0):\n",
    "    # Dimensions\n",
    "    k_endog, nobs = y.shape\n",
    "    k_states = T.shape[0]\n",
    "\n",
    "    # Allocate memory for variables\n",
    "    filtered_state = np.zeros((k_states, nobs))\n",
    "    filtered_state_cov = np.zeros((k_states, k_states, nobs))\n",
    "    predicted_state = np.zeros((k_states, nobs+1))\n",
    "    predicted_state_cov = np.zeros((k_states, k_states, nobs+1))\n",
    "    forecast = np.zeros((k_endog, nobs))\n",
    "    forecast_error = np.zeros((k_endog, nobs))\n",
    "    forecast_error_cov = np.zeros((k_endog, k_endog, nobs))\n",
    "    loglikelihood = np.zeros((nobs+1,))\n",
    "\n",
    "    # Copy initial values to predicted\n",
    "    predicted_state[:, 0] = a_0\n",
    "    predicted_state_cov[:, :, 0] = P_0\n",
    "\n",
    "    # Kalman filter iterations\n",
    "    for t in range(nobs):\n",
    "\n",
    "        # Forecast for time t\n",
    "        forecast[:, t] = np.dot(Z, predicted_state[:, t])\n",
    "\n",
    "        # Forecast error for time t\n",
    "        forecast_error[:, t] = y[:, t] - forecast[:, t]\n",
    "\n",
    "        # Forecast error covariance matrix and inverse for time t\n",
    "        tmp1 = np.dot(predicted_state_cov[:, :, t], Z.T)\n",
    "        forecast_error_cov[:, :, t] = (\n",
    "            np.dot(Z, tmp1) + H\n",
    "        )\n",
    "        forecast_error_cov_inv = np.linalg.inv(forecast_error_cov[:, :, t])\n",
    "        determinant = np.linalg.det(forecast_error_cov[:, :, t])\n",
    "\n",
    "        # Filtered state for time t\n",
    "        tmp2 = np.dot(forecast_error_cov_inv, forecast_error[:,t])\n",
    "        filtered_state[:, t] = (\n",
    "            predicted_state[:, t] +\n",
    "            np.dot(tmp1, tmp2)\n",
    "        )\n",
    "\n",
    "        # Filtered state covariance for time t\n",
    "        tmp3 = np.dot(forecast_error_cov_inv, Z)\n",
    "        filtered_state_cov[:, :, t] = (\n",
    "            predicted_state_cov[:, :, t] -\n",
    "            np.dot(\n",
    "                np.dot(tmp1, tmp3),\n",
    "                predicted_state_cov[:, :, t]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Loglikelihood\n",
    "        loglikelihood[t] = -0.5 * (\n",
    "            np.log((2*np.pi)**k_endog * determinant) +\n",
    "            np.dot(forecast_error[:, t], tmp2)\n",
    "        )\n",
    "\n",
    "        # Predicted state for time t+1\n",
    "        predicted_state[:, t+1] = np.dot(T, filtered_state[:, t])\n",
    "\n",
    "        # Predicted state covariance matrix for time t+1\n",
    "        tmp4 = np.dot(T, filtered_state_cov[:, :, t])\n",
    "        predicted_state_cov[:, :, t+1] = np.dot(tmp4, T.T) + Q\n",
    "        \n",
    "        predicted_state_cov[:, :, t+1] = (\n",
    "            predicted_state_cov[:, :, t+1] + predicted_state_cov[:, :, t+1].T\n",
    "        ) / 2\n",
    "\n",
    "    return (\n",
    "        filtered_state, filtered_state_cov,\n",
    "        predicted_state, predicted_state_cov,\n",
    "        forecast, forecast_error, forecast_error_cov,\n",
    "        loglikelihood\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So why then did I write nearly 15,000 lines of code to\n",
    "contribute Kalman filtering and state-space models to the\n",
    "Statsmodels project?\n",
    "\n",
    "1. **Performance**: It should run fast\n",
    "2. **Wrapping**: It should be easy to use\n",
    "3. **Testing**: It should run correctly\n",
    "\n",
    "### Performance\n",
    "\n",
    "The Kalman filter basically consists of iterations (loops) and\n",
    "matrix operations. It is well known that loops perform poorly\n",
    "in interpreted languages like Python<sup>1</sup>, and also that\n",
    "matrix operations are ultimately performed by the highly\n",
    "optimized [BLAS](http://www.netlib.org/blas/) and\n",
    "[LAPACK](http://www.netlib.org/lapack/) libraries, regardless\n",
    "of the high-level programming language used.<sup>2</sup> This\n",
    "suggests two things:\n",
    "\n",
    "- Fast code should be compiled (not interpreted)\n",
    "- Fast code should call the BLAS / LAPACK libraries as soon\n",
    "   as possible (not through intermediate functions)\n",
    "\n",
    "These two things are possible using\n",
    "[Cython](http://cython.org/), a simple extension of Python\n",
    "syntax that allows compilation to C and direct interaction with\n",
    "BLAS and LAPACK. All of the heavy lifting of the Kalman\n",
    "filtering I contributed to Statsmodels is performed in Cython,\n",
    "which allows for very fast execution.\n",
    "\n",
    "It might seem like this approach eliminates the whole benefit\n",
    "of using a high-level language like Python - in fact, why not\n",
    "just use C or Fortran if we're going to ultimately compile the\n",
    "code? First, Cython is quite similar to Python, so future\n",
    "maintenance is easier, but more importantly end-user Python\n",
    "code can interact with it directly. In this way, we get the\n",
    "best of both worlds: the speed of compiled code where\n",
    "performance is needed and the ease of interpreted code where it\n",
    "isn't.\n",
    "\n",
    "An $AR(1)$ model can be written in state space form as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    y_t & = \\alpha_t \\\\\\\n",
    "    \\alpha_{t+1} & = \\phi_1 \\alpha_t + \\eta_t \\qquad \\eta_t \\sim N(0, \\sigma_\\eta^2)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "and it can specified in Python and the Kalman filter applied\n",
    "using the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.signal import lfilter\n",
    "\n",
    "# Parameters\n",
    "nobs = 100\n",
    "phi = 0.5\n",
    "sigma2 = 1.0\n",
    "\n",
    "# Example dataset\n",
    "np.random.seed(1234)\n",
    "eps = np.random.normal(scale=sigma2**0.5, size=nobs)\n",
    "y = lfilter([1], [1, -phi], eps)[np.newaxis, :]\n",
    "\n",
    "# State space\n",
    "Z = np.array([1.])\n",
    "H = np.array([0.])\n",
    "T = np.array([phi])\n",
    "Q = np.array([sigma2])\n",
    "\n",
    "# Initial state distribution\n",
    "a_0 = np.array([0.])\n",
    "P_0 = np.array([sigma2 / (1 - phi**2)])\n",
    "\n",
    "# Run the Kalman filter\n",
    "res = kalman_filter(y, Z, H, T, Q, a_0, P_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the above Kalman filter with the implementation in\n",
    "Statsmodels for the $AR(1)$ model yields the following runtimes\n",
    "in milliseconds for a single filter application, where $nobs$\n",
    "is the length of the time series (reasonable measures were\n",
    "taken to ensure these timings are meaningful, but not\n",
    "extraordinary measures):\n",
    "\n",
    "\n",
    "| `nobs`        | Python (ms) | MATLAB (ms) | Cython (ms)   |\n",
    "|---------------|-------------|-------------|---------------|\n",
    "| $10$   &nbsp; | $0.742$     | $0.326$     | $0.106$       |\n",
    "| $10^2$        | $6.39$      | $3.040$     | $0.161$       |\n",
    "| $10^3$        | $67.1$      | $32.5$      | $0.668$       |\n",
    "| $10^4$        | $662.0$     | $311.3$     | $6.1$         |\n",
    "\n",
    "Across hundreds or thousands of iterations (as in maximum\n",
    "likelihood estimation or MCMC methods), these differences can\n",
    "be substantial. Also, other Kalman filtering methods, such as\n",
    "the univariate approach of Koopman and Durbin (2000) used with\n",
    "large dimensional observations $y_t$, can add additional inner\n",
    "loops, increasing the importance of compiled code.\n",
    "\n",
    "### Wrapping\n",
    "\n",
    "One of the main reaons that using Python or MATLAB is\n",
    "preferrable to C or Fortran is that code in higher-level \n",
    "lanaguages is more expressive and more readable. Even though\n",
    "the performance sensitive code has been written in Cython, we\n",
    "want to take advantage of the high-level language features in\n",
    "Python proper to make specifying, filtering, and estimating\n",
    "parameters of state space models as natural as possible. For\n",
    "example, an $ARMA(1,1)$ model can be written in state-space\n",
    "form as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    y_t & = \\begin{bmatrix} 1 & \\theta_1 \\end{bmatrix} \\begin{bmatrix} \\alpha_{1t} \\\\ \\alpha_{2t} \\end{bmatrix} \\\\\\\n",
    "    \\begin{bmatrix} \\alpha_{1t+1} \\\\ \\alpha_{2t+1} \\end{bmatrix} & = \\begin{bmatrix}\n",
    "    \\phi_1 & 0 \\\\\n",
    "    1 & 0\n",
    "    \\end{bmatrix} \\begin{bmatrix} \\alpha_{1t} \\\\ \\alpha_{2t} \\end{bmatrix} + \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\eta_t \\qquad \\eta_t \\sim N(0, \\sigma_\\eta^2)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\theta\\_1$, $\\phi\\_1$, and $\\sigma\\_\\eta^2$ are unknown\n",
    "parameters. Estimating them via MLE has been made very\n",
    "easy in the Statsmodels state space library; the model can be\n",
    "specified and estimated with the following code\n",
    "\n",
    "**Note**: this code has been updated on July 31, 2015 to\n",
    "reflect an update to the Statsmodels code base.\n",
    "\n",
    "**Note**: this code has been updated on June 17, 2016 to\n",
    "reflect a further update to the Statsmodels code base, and\n",
    "also to estimate an ARMA(1,1) model as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Statespace Model Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 1000\n",
      "Model:                         ARMA11   Log Likelihood               -1389.992\n",
      "Date:                Sun, 22 Jan 2017   AIC                           2785.984\n",
      "Time:                        15:40:18   BIC                           2800.707\n",
      "Sample:                             0   HQIC                          2791.580\n",
      "                               - 1000                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "param.0       -0.0203      0.072     -0.284      0.776      -0.161       0.120\n",
      "param.1        0.4617      0.065      7.140      0.000       0.335       0.588\n",
      "param.2        0.9436      0.042     22.413      0.000       0.861       1.026\n",
      "===================================================================================\n",
      "Ljung-Box (Q):                       25.04   Jarque-Bera (JB):                 0.16\n",
      "Prob(Q):                              0.97   Prob(JB):                         0.92\n",
      "Heteroskedasticity (H):               1.05   Skew:                            -0.03\n",
      "Prob(H) (two-sided):                  0.63   Kurtosis:                         3.01\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import lfilter\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# True model parameters for an AR(1)\n",
    "nobs = int(1e3)\n",
    "true_phi = 0.5\n",
    "true_sigma = 1**0.5\n",
    "\n",
    "# Simulate a time series\n",
    "np.random.seed(1234)\n",
    "disturbances = np.random.normal(0, true_sigma, size=(nobs,))\n",
    "endog = lfilter([1], np.r_[1, -true_phi], disturbances)\n",
    "\n",
    "# Construct the model for an ARMA(1,1)\n",
    "class ARMA11(sm.tsa.statespace.MLEModel):\n",
    "    def __init__(self, endog):\n",
    "        # Initialize the state space model\n",
    "        super(ARMA11, self).__init__(endog, k_states=2, k_posdef=1,\n",
    "                                     initialization='stationary')\n",
    "\n",
    "        # Setup the fixed components of the state space representation\n",
    "        self['design'] = [1., 0]\n",
    "        self['transition'] = [[0, 0],\n",
    "                              [1., 0]]\n",
    "        self['selection', 0, 0] = 1.\n",
    "\n",
    "    # Describe how parameters enter the model\n",
    "    def update(self, params, transformed=True, **kwargs):\n",
    "        params = super(ARMA11, self).update(params, transformed, **kwargs)\n",
    "\n",
    "        self['design', 0, 1] = params[0]\n",
    "        self['transition', 0, 0] = params[1]\n",
    "        self['state_cov', 0, 0] = params[2]\n",
    "\n",
    "    # Specify start parameters and parameter names\n",
    "    @property\n",
    "    def start_params(self):\n",
    "        return [0.,0.,1]  # these are very simple\n",
    "\n",
    "# Create and fit the model\n",
    "mod = ARMA11(endog)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas the above example showed an ad-hoc creation and\n",
    "estimation of a specific model, the power of object-oriented\n",
    "programming in Python can be leveraged to create generic and\n",
    "reusable estimation classes. For example, for the common class\n",
    "of (Seasonal) Autoregressive Integrated Moving Average models\n",
    "(optionally with exogenous regressors), an `SARIMAX` class has\n",
    "been written to automate the creation and estimation of those\n",
    "types of models. For example, an\n",
    "$SARIMA(1,1,1) \\times (0,1,1,4)$ model of GDP can be specified\n",
    "and estimated as (an added bonus is that we can download the\n",
    "GDP data on-the-fly from FRED using Pandas):\n",
    "\n",
    "**Note**: this code has been updated on June 17, 2016 to\n",
    "reflect an update to the Statsmodels code base and to use the\n",
    "`pandas_datareader` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Statespace Model Results                                \n",
      "=========================================================================================\n",
      "Dep. Variable:                             GDPC1   No. Observations:                  224\n",
      "Model:             SARIMAX(1, 1, 1)x(0, 1, 1, 4)   Log Likelihood               -1222.487\n",
      "Date:                           Sun, 22 Jan 2017   AIC                           2452.974\n",
      "Time:                                   15:40:39   BIC                           2466.620\n",
      "Sample:                               01-01-1959   HQIC                          2458.482\n",
      "                                    - 10-01-2014                                         \n",
      "Covariance Type:                             opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ar.L1          0.6636      0.117      5.695      0.000       0.435       0.892\n",
      "ma.L1         -0.3247      0.143     -2.263      0.024      -0.606      -0.043\n",
      "ma.S.L4       -0.9332      0.034    -27.594      0.000      -0.999      -0.867\n",
      "sigma2      3981.5479    286.690     13.888      0.000    3419.645    4543.450\n",
      "===================================================================================\n",
      "Ljung-Box (Q):                       44.38   Jarque-Bera (JB):               140.86\n",
      "Prob(Q):                              0.29   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               2.94   Skew:                            -0.81\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                         6.58\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from pandas_datareader.data import DataReader\n",
    "\n",
    "gdp = DataReader('GDPC1', 'fred', start='1959', end='12-31-2014')\n",
    "\n",
    "# Create the model, here an SARIMA(1,1,1) x (0,1,1,4) model\n",
    "mod = sm.tsa.SARIMAX(gdp, order=(1,1,1), seasonal_order=(0,1,1,4))\n",
    "\n",
    "# Fit the model via maximum likelihood\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of built-in model should be familiar to those who\n",
    "work with programs like Stata (which also has a built-in\n",
    "SARIMAX model). The benefit of Python and Statsmodels is that\n",
    "you can build *your own* classes of models which behave just\n",
    "as smoothly and seamlessly as those that are \"built-in\". By\n",
    "building on top of the state space functionality in\n",
    "Statsmodels, you get a lot for free while still retaining the\n",
    "flexibility to write any kind of model you want.\n",
    "\n",
    "For example, a local linear trend model can be created for\n",
    "re-use in the following way:\n",
    "\n",
    "**Note**: this code has been updated on June 17, 2016 to\n",
    "reflect an update to the Statsmodels code base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Univariate Local Linear Trend Model\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "class LocalLinearTrend(sm.tsa.statespace.MLEModel):\n",
    "    def __init__(self, endog, trend=True):\n",
    "        # Model properties\n",
    "        self.trend = trend\n",
    "\n",
    "        # Model order\n",
    "        k_states = 2\n",
    "        k_posdef = 1 + self.trend\n",
    "\n",
    "        # Initialize the statespace\n",
    "        super(LocalLinearTrend, self).__init__(\n",
    "            endog, k_states=k_states, k_posdef=k_posdef,\n",
    "        )\n",
    "\n",
    "        # Initialize the matrices\n",
    "        self['design'] = np.array([1, 0])\n",
    "        self['transition'] = np.array([[1, 1],\n",
    "                                       [0, 1]])\n",
    "        self['selection'] = np.eye(k_states)[:,:k_posdef]\n",
    "\n",
    "        # Initialize the state space model as approximately diffuse\n",
    "        self.initialize_approximate_diffuse()\n",
    "        # Because of the diffuse initialization, burn first two loglikelihoods\n",
    "        self.loglikelihood_burn = 2\n",
    "\n",
    "        # Cache some indices\n",
    "        self._state_cov_idx = ('state_cov',) + np.diag_indices(k_posdef)\n",
    "\n",
    "        # The parameters depend on whether or not we have a trend\n",
    "        param_names = ['sigma2.measurement', 'sigma2.level']\n",
    "        if self.trend:\n",
    "            param_names += ['sigma2.trend']\n",
    "        self._param_names = param_names\n",
    "\n",
    "    @property\n",
    "    def start_params(self):\n",
    "        return [0.1] * (2 + self.trend)\n",
    "\n",
    "    def transform_params(self, unconstrained):\n",
    "        return unconstrained**2\n",
    "\n",
    "    def untransform_params(self, constrained):\n",
    "        return constrained**0.5\n",
    "\n",
    "    def update(self, params, *args, **kwargs):\n",
    "        params = super(LocalLinearTrend, self).update(params, *args, **kwargs)\n",
    "\n",
    "        # Observation covariance\n",
    "        self['obs_cov',0,0] = params[0]\n",
    "\n",
    "        # State covariance\n",
    "        self[self._state_cov_idx] = params[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a generic class that can fit local linear trend\n",
    "models (if `trend=True`) and also local level models (if\n",
    "`trend=False`). For example, we can model the annual flow\n",
    "volume of the Nile river using a local linear trend model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Statespace Model Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 volume   No. Observations:                  100\n",
      "Model:               LocalLinearTrend   Log Likelihood                -629.858\n",
      "Date:                Sun, 22 Jan 2017   AIC                           1265.716\n",
      "Time:                        15:41:27   BIC                           1273.532\n",
      "Sample:                    01-01-1871   HQIC                          1268.879\n",
      "                         - 01-01-1970                                         \n",
      "Covariance Type:                  opg                                         \n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "sigma2.measurement  1.469e+04   2756.914      5.330      0.000    9291.260    2.01e+04\n",
      "sigma2.level        1747.4389   1211.919      1.442      0.149    -627.879    4122.756\n",
      "sigma2.trend        3.097e-06      4.254   7.28e-07      1.000      -8.339       8.339\n",
      "===================================================================================\n",
      "Ljung-Box (Q):                       36.16   Jarque-Bera (JB):                 0.05\n",
      "Prob(Q):                              0.64   Prob(JB):                         0.98\n",
      "Heteroskedasticity (H):               0.62   Skew:                             0.05\n",
      "Prob(H) (two-sided):                  0.17   Kurtosis:                         3.05\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "y = sm.datasets.nile.load_pandas().data\n",
    "y.index = pd.date_range('1871', '1970', freq='AS')\n",
    "\n",
    "mod1 = LocalLinearTrend(y['volume'], trend=True)\n",
    "res1 = mod1.fit()\n",
    "print res1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks as though the presense of a stochastic trend\n",
    "is not adding anything to the model (and the parameter is not\n",
    "estimated well in any case) - refitting without the trend is\n",
    "easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Statespace Model Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 volume   No. Observations:                  100\n",
      "Model:               LocalLinearTrend   Log Likelihood                -629.858\n",
      "Date:                Sun, 22 Jan 2017   AIC                           1263.717\n",
      "Time:                        15:41:45   BIC                           1268.927\n",
      "Sample:                    01-01-1871   HQIC                          1265.825\n",
      "                         - 01-01-1970                                         \n",
      "Covariance Type:                  opg                                         \n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "sigma2.measurement  1.472e+04   2734.512      5.383      0.000    9360.283    2.01e+04\n",
      "sigma2.level        1742.4785   1117.075      1.560      0.119    -446.949    3931.906\n",
      "===================================================================================\n",
      "Ljung-Box (Q):                       36.17   Jarque-Bera (JB):                 0.04\n",
      "Prob(Q):                              0.64   Prob(JB):                         0.98\n",
      "Heteroskedasticity (H):               0.62   Skew:                             0.04\n",
      "Prob(H) (two-sided):                  0.17   Kurtosis:                         3.05\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "mod2 = LocalLinearTrend(y['volume'], trend=False)\n",
    "res2 = mod2.fit()\n",
    "print res2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of constructing our own custom class, this particular example could be estimated using the `UnobservedComponents` model in the Statsmodels state space library.\n",
    "\n",
    "### Testing\n",
    "\n",
    "It is no good to have fast code that is easy to use if it gives\n",
    "the wrong answer. For that reason, a large part of creating\n",
    "production ready code is constructing unit tests comparing\n",
    "the module's output to known values to make sure everything\n",
    "works. The state space model code in Statsmodels has 455 unit\n",
    "tests covering everything from the filter output\n",
    "(`filtered_state`, `logliklelihood`, etc.) to state space\n",
    "creation (e.g. the `SARIMAX` class) and maximum likelihood\n",
    "estimation (estimated parameters, maximized likelihood values,\n",
    "standard errors, etc.).\n",
    "\n",
    "### Bibliography\n",
    "\n",
    "Durbin, James, and Siem Jan Koopman. 2012.\n",
    "Time Series Analysis by State Space Methods: Second Edition.\n",
    "Oxford University Press.\n",
    "\n",
    "Koopman, S. J., and J. Durbin. 2000.\n",
    "“Fast Filtering and Smoothing for Multivariate State Space Models.”\n",
    "Journal of Time Series Analysis 21 (3): 281–96.\n",
    "\n",
    "### Footnotes\n",
    "\n",
    "[1] This can be improved with a JIT compiler like\n",
    "[Numba](http://numba.pydata.org/).\n",
    "\n",
    "[2] Python, MATLAB, Mathematica, Stata, Gauss, Ox, etc. all\n",
    "ultimately rely on BLAS and LAPACK libraries for performing\n",
    "operations on matrices.\n",
    "\n",
    "[3] See Durbin and Koopman (2012) for notation.\n",
    "\n",
    "[4] A [proposal](http://legacy.python.org/dev/peps/pep-0465/)\n",
    "is in place to create an infix matrix multiplication\n",
    "operator in Python\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
