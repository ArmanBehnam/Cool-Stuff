{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TODO: Remove unnecessary imports`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense, Conv1D, MaxPool2D, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from keras.optimizers import Adam, SGD, Nadam\n",
    "from time import time\n",
    "from livelossplot import PlotLossesKeras\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "import tensorflow as tf\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "from keijzer import *\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"} # Make sure the axis background of plots is white, this is usefull for the black theme in JupyterLab\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of GPUs available: 1\n"
     ]
    }
   ],
   "source": [
    "# Setup (multi) GPU usage with scalable VRAM\n",
    "num_gpu = setup_multi_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generator\n",
    "In this case it is not a Python generator, just a function that loads the data and outputs the train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>FF</th>\n",
       "      <th>RG</th>\n",
       "      <th>T</th>\n",
       "      <th>gasPower</th>\n",
       "      <th>gasPower_std</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-02-28 12:00:00</td>\n",
       "      <td>9.067500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.183333</td>\n",
       "      <td>6.115723</td>\n",
       "      <td>0.085626</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-02-28 13:00:00</td>\n",
       "      <td>8.684999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>5.238647</td>\n",
       "      <td>0.318250</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-02-28 14:00:00</td>\n",
       "      <td>8.296667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.283333</td>\n",
       "      <td>2.451172</td>\n",
       "      <td>0.041087</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-02-28 15:00:00</td>\n",
       "      <td>6.918334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.516667</td>\n",
       "      <td>3.065186</td>\n",
       "      <td>0.214238</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-02-28 16:00:00</td>\n",
       "      <td>6.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.433333</td>\n",
       "      <td>8.120117</td>\n",
       "      <td>0.014156</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime        FF   RG         T  gasPower  gasPower_std  hour  \\\n",
       "0 2017-02-28 12:00:00  9.067500  0.0  5.183333  6.115723      0.085626    12   \n",
       "1 2017-02-28 13:00:00  8.684999  0.0  5.300000  5.238647      0.318250    13   \n",
       "2 2017-02-28 14:00:00  8.296667  0.0  5.283333  2.451172      0.041087    14   \n",
       "3 2017-02-28 15:00:00  6.918334  0.0  5.516667  3.065186      0.214238    15   \n",
       "4 2017-02-28 16:00:00  6.583333  0.0  5.433333  8.120117      0.014156    16   \n",
       "\n",
       "   dayofweek  season  \n",
       "0          1       1  \n",
       "1          1       1  \n",
       "2          1       1  \n",
       "3          1       1  \n",
       "4          1       1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"F:\\\\Jupyterlab\\\\Multivariate-time-series-models-in-Keras\\\\data\\\\house_data_processed.csv\", delimiter='\\t', parse_dates=['datetime'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    # Loading the data\n",
    "    df = pd.read_csv(\"F:\\\\Jupyterlab\\\\Multivariate-time-series-models-in-Keras\\\\data\\\\house_data_processed.csv\", delimiter='\\t', parse_dates=['datetime'])\n",
    "    df = df.set_index(['datetime']) \n",
    "\n",
    "    magnitude = 1 # Take this from the 1. EDA & Feauture engineering notebook. It's the factor where gasPower has been scaled with to the power 10.\n",
    "    \n",
    "    # Preprocessing\n",
    "    data = df.copy()\n",
    "    \n",
    "    columns_to_category = ['hour', 'dayofweek', 'season']\n",
    "    data[columns_to_category] = data[columns_to_category].astype('category') # change datetypes to category\n",
    "    \n",
    "    # One hot encoding the dummy variables\n",
    "    data = pd.get_dummies(data, columns=columns_to_category) # One hot encoding the categories\n",
    "    \n",
    "    # Create train and test set\n",
    "    \n",
    "    X = data.drop(['gasPower'], axis=1)\n",
    "    #print('X columns: %s' % list(X.columns))\n",
    "\n",
    "    y = data['gasPower']\n",
    "\n",
    "    #X = np.array(X).reshape(-1,len(X.columns)) # Reshape to required dimensions for sklearn\n",
    "    #y = np.array(y).reshape(-1,1)\n",
    "\n",
    "    train_size = 0.7\n",
    "\n",
    "    split_index = int(data.shape[0]*train_size) # the index at which to split df into train and test\n",
    "\n",
    "    X_train = X[:split_index]\n",
    "    y_train = y[:split_index]\n",
    "\n",
    "    X_test = X[split_index:]\n",
    "    y_test = y[split_index:]\n",
    "    \n",
    "    # Scaling the features\n",
    "    scalerX = StandardScaler(with_mean=True, with_std=True).fit(X_train)\n",
    "\n",
    "    X_train = scalerX.transform(X_train)\n",
    "    X_test = scalerX.transform(X_test)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    seed = 42\n",
    "\n",
    "    # Initialize the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input layer\n",
    "    model.add(Dense(16, input_shape=(X_train.shape[1],), kernel_initializer='TruncatedNormal'))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout({{uniform(0, 1)}}, seed=seed)) \n",
    "\n",
    "    # If we choose 'four', add an additional fourth layer\n",
    "    if {{choice(['three', 'four'])}} == 'four':\n",
    "        model.add(Dense(100))\n",
    "\n",
    "        # We can also choose between complete sets of layers\n",
    "\n",
    "        model.add({{choice([Dropout(0.5), Activation('linear')])}})\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # compiling the sequential model\n",
    "    model.compile(loss='mse', metrics=[mape, smape], optimizer={{choise(['rmsprop', 'adam', 'sgd', 'nadam'])}})\n",
    "    \n",
    "    result = model.fit(X_train, y_train, epochs=10, verbose=2, validation_split=0.3)\n",
    "    \n",
    "    #get the highest validation accuracy of the training epochs\n",
    "    validation_acc = np.amax(result.history['val_mape']) \n",
    "    print('Best validation acc of epoch:', validation_acc)\n",
    "    \n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'F:\\\\Jupyterlab\\\\Multivariate-time-series-models-in-Keras\\\\notebooks\\\\<ipython-input-21-f9c5bf3b4aaf>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f9c5bf3b4aaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m                                           \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                           \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                                           trials=Trials())\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Evalutation of best performing model:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space)\u001b[0m\n\u001b[0;32m     65\u001b[0m                                      \u001b[0mfull_model_string\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                                      verbose=verbose)\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[1;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mmodel_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_model_string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0mmodel_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_hyperopt_model_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnotebook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m     \u001b[0mtemp_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./temp_model.py'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[0mwrite_temp_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mget_hyperopt_model_string\u001b[1;34m(model, data, functions, notebook_name, verbose, stack)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mcalling_script_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalling_script_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m             \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'F:\\\\Jupyterlab\\\\Multivariate-time-series-models-in-Keras\\\\notebooks\\\\<ipython-input-21-f9c5bf3b4aaf>'"
     ]
    }
   ],
   "source": [
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "\n",
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=5,\n",
    "                                          trials=Trials())\n",
    "X_train, Y_train, X_test, Y_test = data()\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(X_test, Y_test))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the architecture\n",
    "model = load_model('models\\\\DNN.best.hdf5', custom_objects={'smape': smape, \n",
    "                                                    'mape': mape}) # Gave an error when loading without 'custom_objects'.. fixed by https://github.com/keras-team/keras/issues/3911\n",
    "\n",
    "# Compile with the same settings as it has been saved with earlier\n",
    "model.compile(loss='mse', metrics=[mape, smape], optimizer=adam)\n",
    "\n",
    "print('FINISHED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_true = y_test.values.reshape(y_test.shape[0], 1)\n",
    "\n",
    "split_index = int(data.shape[0]*train_size)\n",
    "x = data[split_index:]\n",
    "\n",
    "datetime_difference = len(x) - len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(x.index, y_true, '.-', color='red', label='Real values', alpha=0.5)\n",
    "plt.plot(x.index, y_pred, '.-', color='blue', label='Predicted values', alpha=1)\n",
    "\n",
    "plt.ylabel(r'gasPower $\\cdot$ 10$^{-%s}$ [m$^3$/h]' % magnitude, fontsize=14)\n",
    "plt.xlabel('datetime [-]', fontsize=14) #TODO: set x values as actual dates\n",
    "\n",
    "plt.xticks(fontsize=14, rotation=45)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.legend(loc='upper left', borderaxespad=0, frameon=False, fontsize=14, markerscale=3)\n",
    "\n",
    "mse_result, mape_result, smape_result = model.evaluate(X_test, y_test)\n",
    "\n",
    "plt.title('DNN result \\n MSE = %.2f \\n MAPE = %.1f [%%] \\n SMAPE = %.1f [%%]' % (mse_result, mape_result, smape_result), fontsize = 14)\n",
    "\n",
    "#plt.savefig('figures/Feedforward result hourly without dummy variables.png', dpi=1200)\n",
    "print('FINISHED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsample these results to a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make it a df to be able to downsample\n",
    "datetime = x.index\n",
    "print(datetime.shape)\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.shape[0])\n",
    "y_true = y_true.reshape(y_true.shape[0])\n",
    "\n",
    "results = pd.DataFrame(y_true, y_pred) # For some reason y_true becomes the index\n",
    "result = results.reset_index() # Ugly way to fix above problem\n",
    "result.columns = ['y_pred', 'y_true']\n",
    "\n",
    "result['datetime'] = datetime\n",
    "result = result.set_index(['datetime'])\n",
    "\n",
    "# Save the model results for later usage\n",
    "result.to_csv('models\\\\DNN_predictions.csv')\n",
    "\n",
    "result = result.resample('D').sum() # Resample data\n",
    "\n",
    "result = result.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics over the result\n",
    "\n",
    "ytrue = result['y_true']\n",
    "ypred = result['y_pred']\n",
    "n = len(result)\n",
    "\n",
    "# Recalculated the metrics for the downsampled results\n",
    "mse_result = (1/n)*np.sum((ypred - ytrue)**2)\n",
    "mape_result = (100/n) * np.sum(np.abs((ytrue - ypred) / ypred))\n",
    "smape_result = (100/n) * np.sum( np.abs((ytrue - ypred)) / (np.abs(ytrue) + np.abs(ypred)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(result.index, result['y_true'], '.-', color='red', label='Real values', alpha=0.5, ms=10) # ms is markersize\n",
    "plt.plot(result.index, result['y_pred'], '.-', color='blue', label='Predicted values', ms=10)\n",
    "\n",
    "plt.ylabel(r'gasPower $\\cdot$ 10$^{-%s}$ [m$^3$/h]' % magnitude, fontsize=14)\n",
    "plt.xlabel('datetime [-]', fontsize=14) #TODO: set x values as actual dates\n",
    "\n",
    "plt.xticks(fontsize=14, rotation=45)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.legend(loc='upper left', borderaxespad=0, frameon=False, fontsize=14, markerscale=3)\n",
    "\n",
    "plt.title('DNN result \\n MSE = %.2f \\n MAPE = %.1f [%%] \\n SMAPE = %.1f [%%]' % (mse_result, mape_result, smape_result), fontsize = 14)\n",
    "\n",
    "#plt.savefig('figures/LSTM result hourly resampled to daily by sum.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
